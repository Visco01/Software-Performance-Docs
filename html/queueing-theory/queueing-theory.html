<!doctype html>
<html lang="en">
<head>
<title>Queueing Theory</title>
<!-- 2024-03-26 Tue 11:23 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="generator" content="Org-mode">
<meta name="author" content="Pietro Visconti">

<link  href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/js/bootstrap.min.js"></script>
<style>
/* org mode styles on top of twbs */

html {
    position: relative;
    min-height: 100%;
}

body {
    font-size: 18px;
    margin-bottom: 105px;
}

footer {
    position: absolute;
    bottom: 0;
    width: 100%;
    height: 101px;
    background-color: #f5f5f5;
}

footer > div {
    padding: 10px;
}

footer p {
    margin: 0 0 5px;
    text-align: center;
    font-size: 16px;
}

#table-of-contents {
    margin-top: 20px;
    margin-bottom: 20px;
}

blockquote p {
    font-size: 18px;
}

pre {
    font-size: 16px;
}

.footpara {
    display: inline-block;
}

figcaption {
  font-size: 16px;
  color: #666;
  font-style: italic;
  padding-bottom: 15px;
}

/* from twbs docs */

.bs-docs-sidebar.affix {
    position: static;
}
@media (min-width: 768px) {
    .bs-docs-sidebar {
        padding-left: 20px;
    }
}

/* All levels of nav */
.bs-docs-sidebar .nav > li > a {
    display: block;
    padding: 4px 20px;
    font-size: 14px;
    font-weight: 500;
    color: #999;
}
.bs-docs-sidebar .nav > li > a:hover,
.bs-docs-sidebar .nav > li > a:focus {
    padding-left: 19px;
    color: #A1283B;
    text-decoration: none;
    background-color: transparent;
    border-left: 1px solid #A1283B;
}
.bs-docs-sidebar .nav > .active > a,
.bs-docs-sidebar .nav > .active:hover > a,
.bs-docs-sidebar .nav > .active:focus > a {
    padding-left: 18px;
    font-weight: bold;
    color: #A1283B;
    background-color: transparent;
    border-left: 2px solid #A1283B;
}

/* Nav: second level (shown on .active) */
.bs-docs-sidebar .nav .nav {
    display: none; /* Hide by default, but at >768px, show it */
    padding-bottom: 10px;
}
.bs-docs-sidebar .nav .nav > li > a {
    padding-top: 1px;
    padding-bottom: 1px;
    padding-left: 30px;
    font-size: 12px;
    font-weight: normal;
}
.bs-docs-sidebar .nav .nav > li > a:hover,
.bs-docs-sidebar .nav .nav > li > a:focus {
    padding-left: 29px;
}
.bs-docs-sidebar .nav .nav > .active > a,
.bs-docs-sidebar .nav .nav > .active:hover > a,
.bs-docs-sidebar .nav .nav > .active:focus > a {
    padding-left: 28px;
    font-weight: 500;
}

/* Nav: third level (shown on .active) */
.bs-docs-sidebar .nav .nav .nav {
    padding-bottom: 10px;
}
.bs-docs-sidebar .nav .nav .nav > li > a {
    padding-top: 1px;
    padding-bottom: 1px;
    padding-left: 40px;
    font-size: 12px;
    font-weight: normal;
}
.bs-docs-sidebar .nav .nav .nav > li > a:hover,
.bs-docs-sidebar .nav .nav .nav > li > a:focus {
    padding-left: 39px;
}
.bs-docs-sidebar .nav .nav .nav > .active > a,
.bs-docs-sidebar .nav .nav .nav > .active:hover > a,
.bs-docs-sidebar .nav .nav .nav > .active:focus > a {
    padding-left: 38px;
    font-weight: 500;
}

/* Show and affix the side nav when space allows it */
@media (min-width: 992px) {
    .bs-docs-sidebar .nav > .active > ul {
        display: block;
    }
    /* Widen the fixed sidebar */
    .bs-docs-sidebar.affix,
    .bs-docs-sidebar.affix-bottom {
        width: 213px;
    }
    .bs-docs-sidebar.affix {
        position: fixed; /* Undo the static from mobile first approach */
        top: 20px;
    }
    .bs-docs-sidebar.affix-bottom {
        position: absolute; /* Undo the static from mobile first approach */
    }
    .bs-docs-sidebar.affix .bs-docs-sidenav,.bs-docs-sidebar.affix-bottom .bs-docs-sidenav {
        margin-top: 0;
        margin-bottom: 0
    }
}
@media (min-width: 1200px) {
    /* Widen the fixed sidebar again */
    .bs-docs-sidebar.affix-bottom,
    .bs-docs-sidebar.affix {
        width: 263px;
    }
}
</style>
<script>
$(function() {
    'use strict';

    $('.bs-docs-sidebar li').first().addClass('active');

    $(document.body).scrollspy({target: '.bs-docs-sidebar'});

    $('.bs-docs-sidebar').affix();
});
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  displayAlign: "center",
  displayIndent: "2em",
  messageStyle: "none",
  "HTML-CSS": {
    scale: 100,
    styles: {
      ".MathJax_Display": {
        "font-size": "100%"
      }
    }
  },
  "SVG": {
    scale: 100,
    styles: {
      ".MathJax_SVG_Display": {
        "font-size": "100%",
        "margin-left": "-2.281em"
      }
    }
  }
});
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG"></script>
</head>
<body>
<div id="content" class="container">
<div class="row"><div class="col-md-3 col-md-push-9"><nav id="table-of-contents">
<div id="text-table-of-contents" class="bs-docs-sidebar">
<ul class="nav">
<li><a href="#sec-1">1. Terminologies</a></li>
<li><a href="#sec-2">2. Kendall notation</a></li>
<li><a href="#sec-3">3. M/M/1 queueing system</a>
<ul class="nav">
<li><a href="#sec-3-1">3.1. Load factor</a></li>
<li><a href="#sec-3-2">3.2. Expected number of customers</a></li>
<li><a href="#sec-3-3">3.3. Expected response time</a></li>
<li><a href="#sec-3-4">3.4. M/M/1 charts</a></li>
<li><a href="#sec-3-5">3.5. Other useful relations in M/M/1</a></li>
</ul>
</li>
<li><a href="#sec-4">4. M/M/m queueing system</a>
<ul class="nav">
<li><a href="#sec-4-1">4.1. Load factor</a></li>
<li><a href="#sec-4-2">4.2. Expected number of customers</a></li>
<li><a href="#sec-4-3">4.3. Expected response time</a></li>
<li><a href="#sec-4-4">4.4. M/M/m charts</a></li>
</ul>
</li>
<li><a href="#sec-5">5. M/M/\(\infty\) queueing system</a>
<ul class="nav">
<li><a href="#sec-5-1">5.1. Expected number of customers</a></li>
<li><a href="#sec-5-2">5.2. Expected response time</a></li>
</ul>
</li>
<li><a href="#sec-6">6. M/G/1 queueing system</a>
<ul class="nav">
<li><a href="#sec-6-1">6.1. P-K Formula</a></li>
<li><a href="#sec-6-2">6.2. Expected number of customers</a></li>
<li><a href="#sec-6-3">6.3. Expected response time</a></li>
<li><a href="#sec-6-4">6.4. Expected waiting time</a></li>
</ul>
</li>
<li><a href="#sec-7">7. M/G/1/PS queueing system (Processor Sharing policy)</a>
<ul class="nav">
<li><a href="#sec-7-1">7.1. Characteristics</a></li>
<li><a href="#sec-7-2">7.2. Ages of Jobs in the M/G/1/PS System</a></li>
<li><a href="#sec-7-3">7.3. Terminologies</a></li>
<li><a href="#sec-7-4">7.4. Expected response time</a></li>
<li><a href="#sec-7-5">7.5. Conclusions about PS</a></li>
</ul>
</li>
<li><a href="#sec-8">8. Shortest-Remaining-Processing-Time (SRPT)</a></li>
<li><a href="#sec-9">9. Least Attained Service (LAS)</a>
<ul class="nav">
<li><a href="#sec-9-1">9.1. LAS implementation: PS+PS discipline</a></li>
</ul>
</li>
</ul>
</div>
</nav>
</div><div class="col-md-9 col-md-pull-3"><h1 class="title">Queueing Theory</h1>
<p>
Queueing theory is the theory behind what happens when you have lots of jobs,
scarce resources, and subsequently long queues and delays. It is literally the
“theory of queues”: what makes queues appear and how to make them go away.
</p>

<p>
The goals of a queueing theorist are twofold. The first is predicting the
<b>system performance</b>. Although prediction is important, an even more important
goal is finding a superior <b>system design</b> to improve performance.
</p>
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Terminologies</h2>
<div class="outline-text-2" id="text-1">
<blockquote>
<p>
<b>System capacity</b>: it represents the maximum number of jobs the system can
 contain (both waiting and serviced).
</p>
</blockquote>

<blockquote>
<p>
<b>Population size</b>: it represents the number of potential jobs that can access
 the system, i.e. they are willing to enter the system.
</p>
</blockquote>

<blockquote>
<p>
<b>Service discipline</b>: policy through which the jobs are served.
</p>
<ol class="org-ol">
<li><b>FCFS</b> (First Come First Serve);
</li>
<li><b>LCFS</b> (Last Come First Serve);
</li>
<li><b>FCFS/LCFS with preemption</b>: this feature allows to remove the job from the
service and putting it back to the queue;
</li>
<li><b>FCFS/LCFS with preemption and resume</b>: same as previous, but it resumes the
state of the job (it doesn&rsquo;t waste the work done);
</li>
<li><b>PS</b> (Processor Sharing): Simplified Round-Robin;
</li>
<li><b>IS</b> (Delay Center or Infinite Services);
</li>
<li><b>SRPT</b> (Shortest Remaining Processing Time).
</li>
</ol>
</blockquote>

<blockquote>
<p>
<b>Work-conserving discipline</b>: a queueing discipline is work-conserving if:
</p>
<ol class="org-ol">
<li>It never leaves idle a server that is allowed to work;
</li>
<li>It never wastes the work done on a job.
</li>
</ol>
</blockquote>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Kendall notation</h2>
<div class="outline-text-2" id="text-2">
<p>
It&rsquo;s a fast way to represent queueing systems.
</p>

<blockquote>
<p>
\(A/S/m/B/K/SD\)
</p>

<ul class="org-ul">
<li>\(A\): inter-arrival distribution
</li>
<li>\(S\): service distribution
</li>
<li>\(m\): number of servers
</li>
<li>\(B\): system capacity (default: \(\infty\))
</li>
<li>\(K\): population size (default: \(\infty\))
</li>
<li>\(SD\): service discipline (default: FCFS)
</li>
</ul>
</blockquote>

<p>
Abbreviations for \(A\) and \(M\):
</p>
<ul class="org-ul">
<li>\(M\): exponential (Poisson);
</li>
<li>\(D\): deterministic;
</li>
<li>\(G\): general distribution.
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> M/M/1 queueing system</h2>
<div class="outline-text-2" id="text-3">
<p>
The M/M/1 open model begins with the following assumptions:
</p>
<ul class="org-ul">
<li>An average arrival rate \(\lambda\) is known;
</li>
<li>The system is running under an stable condition, i.e. \(\lambda < \mu\);
</li>
</ul>

<p>
<b>M/M/1</b> terminology indicates these features:
</p>
<ul class="org-ul">
<li>Exponential independent inter-arrival times (Poisson arrivals);
</li>
<li>Exponential independent service times;
</li>
<li>Single server, infinite buffer, FCFS discipline.
</li>
</ul>
</div>
<div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1"><span class="section-number-3">3.1</span> Load factor</h3>
<div class="outline-text-3" id="text-3-1">
<p>
The load factor is defined as follows: \[\rho=\frac{\lambda}{\mu}\] and it
represents the ratio between the arrival rate and the service rate.
</p>

<p>
We already observed that the queue is stable, i.e. \(\rho < 1\).
</p>

<blockquote>
<p>
The steady-state probability of observing n jobs in the queue has a <b>geometric
distribution</b> with ratio \(\rho\).
</p>
</blockquote>
</div>
</div>
<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2"><span class="section-number-3">3.2</span> Expected number of customers</h3>
<div class="outline-text-3" id="text-3-2">
<p>
We have that \[\overline{N}=\frac{\rho}{1-\rho}\]
And the steady-state probability to find the server busy (i.e. number of customers in the service room) is \[U=\rho=E[N_{s}]\]
Recall that \(E[N]=E[N_{s}]+E[N_{q}]\), therefore \[E[N_{q}]=\frac{\rho}{1-\rho}-\rho=\frac{\rho^{2}}{1-\rho}\]
</p>
</div>
</div>
<div id="outline-container-sec-3-3" class="outline-3">
<h3 id="sec-3-3"><span class="section-number-3">3.3</span> Expected response time</h3>
<div class="outline-text-3" id="text-3-3">
<p>
In stability conditions, we have \(X = \lambda\).
We can compute the expected response time by Little’s theorem: \[\overline{R}=E[R]=\frac{\overline{N}}{X}=\frac{1}{\mu-\lambda}\]
We know that \(E[S]=\mu^{-1}=\frac{1}{\mu}\), therefore \[E[W]=E[R]-E[S]=\frac{1}{\mu-\lambda}-\frac{1}{\mu}=\frac{\lambda}{\mu(\mu-\lambda)}\]
</p>
</div>
</div>
<div id="outline-container-sec-3-4" class="outline-3">
<h3 id="sec-3-4"><span class="section-number-3">3.4</span> M/M/1 charts</h3>
<div class="outline-text-3" id="text-3-4">

<figure>
<p><img src="../../resources/mm1-ncustomers.png" class="img-responsive" alt="mm1-ncustomers.png">
</p>
</figure>


<figure>
<p><img src="../../resources/mm1-response-time.png" class="img-responsive" alt="mm1-response-time.png">
</p>
<figcaption><span class="figure-number">Figure 2:</span> This chart can be subdivided in three parts: Low Load, Moderate Load, Heavy Load. The last one MUST be avoided due to the exponential response time based on little variations of &lambda;.</figcaption>
</figure>
</div>
</div>
<div id="outline-container-sec-3-5" class="outline-3">
<h3 id="sec-3-5"><span class="section-number-3">3.5</span> Other useful relations in M/M/1</h3>
<div class="outline-text-3" id="text-3-5">
<blockquote>
<p>
<b>Probability to find the empty queue</b>: \(1-\frac{\lambda}{\mu}=1-\rho\)
</p>
</blockquote>

<blockquote>
<p>
<b>Length of idle periods in the system</b>: exponentially distributed with mean
 \(\frac{1}{\lambda}\)
</p>
</blockquote>

<blockquote>
<p>
<b>Average length of busy periods</b>: \(X=\frac{1}{\mu-\lambda}\)
</p>
</blockquote>
</div>
</div>
</div>
<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> M/M/m queueing system</h2>
<div class="outline-text-2" id="text-4">
<p>
In today’s high-volume world, almost no websites, compute centers, or call
centers consist of just a single server. Instead a “server farm” is used. The
server farm is a collection of servers that work together to handle incoming
requests. Each request might be routed to a different server, so that servers
“share” the incoming load. From a practical perspective, server farms are often
preferable to a single “super-fast” server because of their low cost (many slow
servers are cheaper than a single fast one) and their flexibility (it is easy to
increase/decrease capacity as needed by adding/removing servers).
</p>

<p>
The first “M” indicates that we have <b>memoryless interarrival times</b>, and the
second “M” indicates <b>memoryless service times</b>. The third field denotes that <b>m
servers share a common pool</b> of arriving jobs. For the M/M/k system, there is no
capacity constraint
</p>


<figure>
<p><img src="../../resources/mmm-queue.png" class="img-responsive" alt="mmm-queue.png">
</p>
</figure>

<p>
Since the incoming stream is completely independent from the system, we denote \[\lambda(n)=\lambda\]
and the service rate is based on the number of \(n\) busy servers
</p>

<p>
\[\mu(n) =
\begin{cases}
  n\mu & \text{n <= m} \\
  m\mu & \text{otherwise}
\end{cases}\]
</p>
</div>
<div id="outline-container-sec-4-1" class="outline-3">
<h3 id="sec-4-1"><span class="section-number-3">4.1</span> Load factor</h3>
<div class="outline-text-3" id="text-4-1">
<p>
In this type of queue system the load factor is defined as follows: \[\rho=\frac{\lambda}{m\mu}\]
Therefore, the system is stable if and only if \(\lambda < m\mu\)
</p>
</div>
</div>
<div id="outline-container-sec-4-2" class="outline-3">
<h3 id="sec-4-2"><span class="section-number-3">4.2</span> Expected number of customers</h3>
<div class="outline-text-3" id="text-4-2">
<p>
Let \(C(m,\frac{\lambda}{\mu})\) be the probability of finding all the servers busy.
</p>

<p>
Assuming stability we have that \(\lambda = X\) where \(X\) is the throughput, and the expected number of customers is derived as follows
</p>

<p>
\[\overline{N}=E[N]=\frac{\rho}{1-\rho}C(m,\frac{\lambda}{\mu})+\frac{\lambda}{\mu}\]
</p>
</div>
</div>
<div id="outline-container-sec-4-3" class="outline-3">
<h3 id="sec-4-3"><span class="section-number-3">4.3</span> Expected response time</h3>
<div class="outline-text-3" id="text-4-3">
<p>
\(\overline{R}\) is derived by Little&rsquo;s theorem as follows \[\overline{R}=E[R]=\frac{C(m,\frac{\lambda}{\mu})}{m\mu-\lambda}+\frac{1}{\mu}\]
</p>
</div>
</div>
<div id="outline-container-sec-4-4" class="outline-3">
<h3 id="sec-4-4"><span class="section-number-3">4.4</span> M/M/m charts</h3>
<div class="outline-text-3" id="text-4-4">

<figure>
<p><img src="../../resources/mmm-ncustomers.png" class="img-responsive" alt="mmm-ncustomers.png">
</p>
</figure>


<figure>
<p><img src="../../resources/mmm-response-time.png" class="img-responsive" alt="mmm-response-time.png">
</p>
</figure>
</div>
</div>
</div>
<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> M/M/\(\infty\) queueing system</h2>
<div class="outline-text-2" id="text-5">
<p>
This dream situation can be modeled by a queueing system with an infinite number
of servers, so that there is always a server to take an incoming job.
</p>

<p>
The interarrival times are Exponential with rate \(\lambda\), the service times are Exponential with rate \(\mu\), and there are an infinite number of servers.
</p>


<figure>
<p><img src="../../resources/mminf-queue.png" class="img-responsive" alt="mminf-queue.png">
</p>
</figure>

<p>
In this case, we denote \[\lambda(n)=\lambda\] and \[\mu(n)=n\mu\]
</p>

<p>
And finally, since we have an infinite number of server, the throughput is
always \(X = \lambda\), i.e. the system is always stable and the jobs don&rsquo;t have
waiting time at all.
</p>
</div>
<div id="outline-container-sec-5-1" class="outline-3">
<h3 id="sec-5-1"><span class="section-number-3">5.1</span> Expected number of customers</h3>
<div class="outline-text-3" id="text-5-1">
<p>
\[\overline{N}=E[N]=\frac{\lambda}{\mu}\]
</p>
</div>
</div>
<div id="outline-container-sec-5-2" class="outline-3">
<h3 id="sec-5-2"><span class="section-number-3">5.2</span> Expected response time</h3>
<div class="outline-text-3" id="text-5-2">
<p>
\[\overline{R}=E[R]=\frac{1}{\mu}\]
</p>
</div>
</div>
</div>
<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6"><span class="section-number-2">6</span> M/G/1 queueing system</h2>
<div class="outline-text-2" id="text-6">
<p>
An M/G/1 queue consists of a single server and queue with Poisson job arrivals
(it holds the PASTA property), where the size (a.k.a. service time) of a job has
a general distribution with <b>mean</b> \(\frac{1}{\mu}\) and <b>variance</b> \(\sigma^{2}\)
and the stability condition is \(\lambda < \mu\), as usual.
</p>

<p>
In the M/G/1 queue, the jobs are pushed in the waiting queue represented by an
<b>infinite buffer</b>.
</p>
</div>
<div id="outline-container-sec-6-1" class="outline-3">
<h3 id="sec-6-1"><span class="section-number-3">6.1</span> P-K Formula</h3>
<div class="outline-text-3" id="text-6-1">
<p>
The formula states that the queue length (how many jobs are in the queue,
waiting to be serviced?) depends not only on the ratio between the expected
service time and the arrival rate, but also on the <b>variance</b> of the service
time.
</p>

<p>
Since the numerator contains the variance, we can conclude that the average
waiting time increases proportionally to the variance, i.e. <b>FCFS sucks with a
great variance</b>.
</p>
</div>
</div>
<div id="outline-container-sec-6-2" class="outline-3">
<h3 id="sec-6-2"><span class="section-number-3">6.2</span> Expected number of customers</h3>
<div class="outline-text-3" id="text-6-2">
<p>
\[\overline{N}=E[N]=\frac{\rho^{2}+\lambda^{2}\sigma^{2}}{2(1-\rho)}+\rho\]
</p>
</div>
</div>
<div id="outline-container-sec-6-3" class="outline-3">
<h3 id="sec-6-3"><span class="section-number-3">6.3</span> Expected response time</h3>
<div class="outline-text-3" id="text-6-3">
<p>
(see waiting time below)
\[\overline{R}=E[R]=\frac{\rho+\lambda\mu\sigma^{2}}{2(\mu -
\lambda)}+\frac{1}{\mu}=\frac{\rho(1+CV^{2})}{2(\mu-\lambda)}+\frac{1}{\mu}\]
</p>
</div>
</div>
<div id="outline-container-sec-6-4" class="outline-3">
<h3 id="sec-6-4"><span class="section-number-3">6.4</span> Expected waiting time</h3>
<div class="outline-text-3" id="text-6-4">
<p>
i.e. response time - service time:
\[E[W]=\frac{\rho+\lambda\mu\sigma^{2}}{2(\mu - \lambda)}\] And, since
\(\sigma^{2}=\frac{CV^{2}}{\mu^{2}}\), we compute
\[E[W]=\frac{\rho+\lambda\mu\frac{CV^{2}}{\mu^{2}}}{2(\mu-\lambda)}\] Then, we
eliminate the 2 \(\mu\) and we have
\[E[W]=\frac{\rho+\frac{\lambda}{\mu}CV^{2}}{2(\mu-\lambda)}=\frac{\rho+\rho*CV^{2}}{2(\mu-\lambda)}=\frac{\rho(1+CV^{2})}{2(\mu-\lambda)}\]
Where <b>CV is the variance</b>.
</p>
</div>
</div>
</div>
<div id="outline-container-sec-7" class="outline-2">
<h2 id="sec-7"><span class="section-number-2">7</span> M/G/1/PS queueing system (Processor Sharing policy)</h2>
<div class="outline-text-2" id="text-7">
<blockquote>
<p>
A policy is <b>preemptive</b> if a job may be stopped partway through its execution
and then resumed at a later point in time from the same point where it was
stopped (this is also called preemptive-resume).
</p>
</blockquote>

<p>
The main problem with the M/G/1 queue is that the mean response time can be very
high when \(\sigma^{2}\) is high (job size variability is high). Intuitively,
short jobs queue up behind long jobs, resulting in long delays.
<b>Processor-Sharing</b>, by contrast, <b>is not negatively affected by high job size
variability</b>.
</p>

<p>
When a short job arrives, it immediately time-shares with all the jobs in the
system. It does not have to wait for long jobs to finish. PS allows short jobs
(which require just a few quanta of service) to get out quickly. time-sharing
the CPU might allow an increase of overall system throughput in a multi-resource
system. Imagine, for example, a multi-resource system, including a CPU, disk,
memory, etc. It is useful to have many jobs running simultaneously (rather than
just one job at a time), because jobs requiring different resources can be
overlapped to increase throughput.
</p>

<blockquote>
<p>
But PS is not better than FCFS for <b>every</b> arrival sequence:
</p>
<ul class="org-ul">
<li>If the service time has a <b>variance smaller than the exponential distribution</b>
with the same mean, then FCFS perfoms better than PS;
</li>
<li>Otherwise, PS performs better;
</li>
<li>If the <b>variance is not known</b>, it is better to opt for PS since it guarantees
the performance indices of the M/M/1 queue independently of the distribution
of the service time
</li>
</ul>
</blockquote>
</div>
<div id="outline-container-sec-7-1" class="outline-3">
<h3 id="sec-7-1"><span class="section-number-3">7.1</span> Characteristics</h3>
<div class="outline-text-3" id="text-7-1">
<ul class="org-ul">
<li><b>Poisson arrival process</b> with intensity \(\lambda\)
</li>
<li><b>General service time</b> with mean \(\mu^{-1}\)
</li>
<li><b>Single server</b>
</li>
<li>Jobs enter in service as soon as they arrive but they share the processor with
the other job in service. In fact, each job receives the same amount of
computational power from the processor
</li>
<li>The waiting time is defined as the difference between the response time and
the service time
</li>
</ul>

<blockquote>
<p>
<b>Insensitivity</b> of the M/G/1/PS queue: the performance indices depend only on
 the mean on the service time and the following moments are irrelevant (this is
 very different from the M/G/1 whose expected performance indeces depend on the
 variance of the service time).
</p>
</blockquote>
</div>
</div>
<div id="outline-container-sec-7-2" class="outline-3">
<h3 id="sec-7-2"><span class="section-number-3">7.2</span> Ages of Jobs in the M/G/1/PS System</h3>
<div class="outline-text-3" id="text-7-2">
<blockquote>
<p>
The <b>age</b> of a job is the total service it has received so far. By definition,
<b>0 &lt;= age(j) &lt;= size(j)</b>, where age(j) denotes the age of job j and size(j)
denotes the (original) size of job j.
</p>
</blockquote>
</div>
</div>
<div id="outline-container-sec-7-3" class="outline-3">
<h3 id="sec-7-3"><span class="section-number-3">7.3</span> Terminologies</h3>
<div class="outline-text-3" id="text-7-3">
<ul class="org-ul">
<li>\(E[x]=\mu^{-1}\)
</li>
<li>\(N[x]=\) expected number of jobs with age <b>at most</b> \(x\)
</li>
<li>\(T[x]=\) expected time spent in the system by a <b>job of size x</b> (i.e. bigger or
equal than x)
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-7-4" class="outline-3">
<h3 id="sec-7-4"><span class="section-number-3">7.4</span> Expected response time</h3>
<div class="outline-text-3" id="text-7-4">
<p>
We have the expected <b>conditioned</b> response time \[T[x]=\frac{x}{1-\rho}\] and
the expected response time \[\overline{R}=E[R]=\frac{1}{\mu-\lambda}\] which
is <b>the same of M/M/1 queue</b> (due to insensivity).
</p>
</div>
</div>
<div id="outline-container-sec-7-5" class="outline-3">
<h3 id="sec-7-5"><span class="section-number-3">7.5</span> Conclusions about PS</h3>
<div class="outline-text-3" id="text-7-5">
<p>
The expected slowdown for a job of size x under the M/G/1/PS is a constant,
independent of the size x. Remember that for non-preemptive non-size-based
scheduling, the mean slowdown for small jobs was greater than the mean slowdown
for large jobs. By contrast, under PS, all jobs have same slowdown. For this
reason, people always refer to PS as <b>fair scheduling</b>.
</p>
</div>
</div>
</div>
<div id="outline-container-sec-8" class="outline-2">
<h2 id="sec-8"><span class="section-number-2">8</span> Shortest-Remaining-Processing-Time (SRPT)</h2>
<div class="outline-text-2" id="text-8">
<p>
Under SRPT, at all times the server is working on that <b>job with the shortest remaining
processing time</b>. The SRPT policy is preemptive so that a new arrival
will preempt the current job serving if the new arrival has a shorter remaining
processing time.
</p>

<p>
Observe that, under SRPT, once a job, j, starts running, it can only be
preempted by a new arrival whose size is shorter than j’s remaining time. In
particular, any jobs that are in the system with j, while j is running, will
never run before j completes.
</p>

<p>
The assumption of this class of schedulers is that <b>we know the service time of
the jobs</b> as soon as they arrive at the system, <b>in advance</b> (not applicable in
many contexts).
</p>

<p>
At each epoch, the job with the smallest remaining processing (service) time
will be served: in this way, small jobs overtake large jobs. This approach
reduces the expected response time.
</p>

<p>
In general, we have these relations between SRPT and PS, given the size of a
job:
</p>

<p>
\[\text{SRPT vs PS} = \begin{cases} \overline{R}^{SRPT} <= \overline{R}^{PS} &
\text{small job size} \\ \overline{R}^{SRPT} >= \overline{R}^{PS} & \text{big
job size} \end{cases}\]
</p>

<p>
From this relation, we can define:
</p>
<blockquote>
<p>
<b>All-can-win-theory</b>: given M/G/1/PS and M/G/1/SRPT queues with the same
 parameters, if \(\rho<0.5\) then, for all \(x\): \[\overline{R}^{SRPT}(x) <=
 \overline{R}^{PS}(x)\]
</p>

<p>
This statement is true <b>until</b> \(\rho<=0.96\)
</p>
</blockquote>
</div>
</div>
<div id="outline-container-sec-9" class="outline-2">
<h2 id="sec-9"><span class="section-number-2">9</span> Least Attained Service (LAS)</h2>
<div class="outline-text-2" id="text-9">
<blockquote>
<p>
<b>Age based disciplines</b> (in general):
</p>
<ul class="org-ul">
<li>At each epoch, we take the decision on the job(s) to serve based on the amount
of work they have received up to that moment
</li>
<li>In general we tend to favor the jobs that have received the smallest amount of
work: the bet is that those who have obtained a lot of work, the will ask even
more
</li>
<li>These disciplines work well when the service times are heavily tailed
</li>
</ul>
</blockquote>

<p>
LAS is a discipline is with <b>preemption and resume</b>, in which at each epoch, the
scheduling discipline works as a PS only on the jobs that have recevied the
least amount of service.
</p>

<blockquote>
<p>
<b>Hazard rate</b>: if the hazard rate of a random variable is <b>monotonically
 decreasing</b>, it means that as time passes the time to completion increases =&gt; in
 terms of service time, it means that <b>if we have given a lot of service to a
 job, this will probably need even more work (!)</b>
</p>
</blockquote>

<p>
LAS is the optimal scheduling discipline <b>if we do not know the job size in advance</b>
(or its distribution) but the job size has monotonically decreasing
hazard rate. We use it when we have <b>many small jobs</b> and a <b>few huge jobs</b> but we
cannot say in advance who is small and who is big.
</p>
</div>
<div id="outline-container-sec-9-1" class="outline-3">
<h3 id="sec-9-1"><span class="section-number-3">9.1</span> LAS implementation: PS+PS discipline</h3>
<div class="outline-text-3" id="text-9-1">
<p>
PS+PS workflow:
</p>
<ol class="org-ol">
<li>We maintain <b>two PS queues</b>. Queue 1 has strict priority on Queue 2;
</li>
<li>We define a <b>threshold T</b>;
</li>
<li>When a job arrives it stays in <b>Queue 1</b> until: either it finishes its job and
hence it leaves the queue, or <b>it reaches the recevied work T</b>. In the latter
case it is moved to Queue 2;
</li>
<li>If more than a job is in Queue 1, they are served in PS. Same for Queue 2.
</li>
</ol>
</div>
</div>
</div>
</div></div></div>
<footer id="postamble" class="">
<div><p class="author">Author: Pietro Visconti</p>
<p class="date">Created: 2024-03-26 Tue 11:23</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 29.3 (<a href="http://orgmode.org">Org-mode</a> 9.7)</p>
</div>
</footer>
</body>
</html>
